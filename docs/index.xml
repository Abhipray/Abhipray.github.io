<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>embedded sigproc</title>
    <link>https://abhipray.com/</link>
    <description>Recent content on embedded sigproc</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 Sep 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://abhipray.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>What is the state of a system? Linear Time-Invariant Systems (LTI) vs Linear Dynamical Systems (LDS)</title>
      <link>https://abhipray.com/posts/sigproc/lti_lds/</link>
      <pubDate>Sat, 07 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://abhipray.com/posts/sigproc/lti_lds/</guid>
      <description>Suggested reading: On linearity It is often easier to understand a concept if it can be connected to some other familiar concept. Like most electrical engineers, I was introduced to Linear Time-Invariant systems/filters in the framework of analyzing electrical signals and circuits. I recently took a class on linear dynamical systems which generalizes the notion of LTI systems using state-space. In this set of notes, I want to make the connection between LTI systems and Linear Dynamical Systems (LDS).</description>
    </item>
    
    <item>
      <title>Tactile Vision &amp; Gray code</title>
      <link>https://abhipray.com/posts/sigproc/tactile_vision/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://abhipray.com/posts/sigproc/tactile_vision/</guid>
      <description>Tactile Vision &amp;amp; Gray code I took a break from my series on speech enhancement to work on a project for an Information Theory class. The project involved designing algorithms to translate images to vibration patterns felt on the chest. The work is summarized on the blog for the class here: https://theinformaticists.com/2019/03/22/tactile-vision1-0-seeing-the-world-through-vibrations/. There are lots of other really cool projects out there so do check it out!
As part of the project, I implemented some algorithms to generate Gray codes.</description>
    </item>
    
    <item>
      <title>Classical Speech Enhancement Part 1: Spectral subtraction</title>
      <link>https://abhipray.com/posts/sigproc/classic_speech_enhancement/spectral_subtraction/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://abhipray.com/posts/sigproc/classic_speech_enhancement/spectral_subtraction/</guid>
      <description>This is part 1 in a series of three posts that implement three classical DSP methods of enhancing speech in audio recordings in Python. It uses slides and re-implements code from a source separation tutorial that can be found here. The post is largely a narration of the material in the link. The three methods are spectral subtraction, Wiener filtering and probabilistic estimation (Ephraim-Malah).
The general framework The speech enhancement problem is posed as a source separation problem - given a mixture of noise ($d[n]$) and signal ($x[n]$), separate the two.</description>
    </item>
    
    <item>
      <title>On linearity: straight lines, linear operators &amp; the Fourier transform</title>
      <link>https://abhipray.com/posts/sigproc/linearity/</link>
      <pubDate>Mon, 31 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://abhipray.com/posts/sigproc/linearity/</guid>
      <description>The list of engineering ideas centered on linearity is endless: linear regression, linear time-invariant (LTI) filter, linear dynamical system, linearization, support vector machines, circuit theory/network analysis etc. Most of these ideas are introduced with a cursorsy view of the significance of linearity. In this post, I want to flip the perspective and make linearity the central theme and elucidate how other ideas depend on it.
We probably all think straight line when we think of the word linear.</description>
    </item>
    
    <item>
      <title>PDM-PCM conversion &amp; PDM&#39;s connection to neurons</title>
      <link>https://abhipray.com/posts/sigproc/pdm_pcm_conversion/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://abhipray.com/posts/sigproc/pdm_pcm_conversion/</guid>
      <description>Background In the context of digital audio systems, PDM is a common interface between microphones and microcontrollers/signal processors. PDM signals represent analog audio signals by sampling the analog microphone waveform at a very high rate with a single bit resolution (on/off) for the amplitude. This encodes the analog signal in the density of the pulses and hence the name, Pulse Density Modulation.
For example, if you want the microphone to record an analog audio signal with a bandwidth of 24KHz (FNyquist), you sample it at say 3.</description>
    </item>
    
  </channel>
</rss>